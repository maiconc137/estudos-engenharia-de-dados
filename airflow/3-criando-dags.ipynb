{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estrutura de uma DAG no Airflow\n",
        "\n",
        "Uma **DAG (Directed Acyclic Graph)** no Airflow define um pipeline de tarefas. É composta por um conjunto de tarefas e as dependências entre elas. A DAG determina a ordem e as condições em que as tarefas devem ser executadas.\n",
        "\n",
        "As principais estruturas de uma DAG incluem:\n",
        "\n",
        "- **`dag_id`**: Um identificador único para a DAG.\n",
        "- **`schedule_interval`**: Define a frequência com que a DAG deve ser executada (diariamente, semanalmente, etc.).\n",
        "- **`default_args`**: Argumentos padrões, como o horário de início, dependências, e se a DAG deve ser retroativa.\n",
        "- **`tasks`**: Tarefas que são executadas dentro da DAG.\n",
        "- **Dependências entre tarefas**: Definem a ordem de execução entre as tarefas.\n",
        "\n",
        "---\n",
        "\n",
        "**Exemplo básico de uma DAG:**\n",
        "\n",
        "1. Definir a DAG e seus argumentos básicos.\n",
        "2. Criar tarefas individuais.\n",
        "3. Definir dependências entre as tarefas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo de DAG simples no Airflow\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.operators.dummy import DummyOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Definindo os argumentos padrão da DAG\n",
        "default_args = {\n",
        "    'owner': 'maicon',\n",
        "    'depends_on_past': False,\n",
        "    'start_date': datetime(2023, 9, 1),\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(minutes=5),\n",
        "}\n",
        "\n",
        "# Definindo a DAG\n",
        "with DAG(\n",
        "    dag_id='exemplo_dag',\n",
        "    default_args=default_args,\n",
        "    description='Exemplo de uma DAG simples',\n",
        "    schedule_interval=timedelta(days=1),\n",
        "    catchup=False,  # Não executa execuções passadas\n",
        ") as dag:\n",
        "\n",
        "    # Criando as tarefas\n",
        "    tarefa_inicial = DummyOperator(task_id='inicio')\n",
        "    tarefa_final = DummyOperator(task_id='fim')\n",
        "\n",
        "    # Definindo as dependências\n",
        "    tarefa_inicial >> tarefa_final  # 'inicio' deve rodar antes de 'fim'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principais Operadores no Airflow\n",
        "\n",
        "No Airflow, os **operadores** são os blocos de construção usados para definir tarefas dentro de um DAG (Directed Acyclic Graph). Cada operador representa uma única tarefa e define o que deve ser executado. Os operadores podem ser divididos em várias categorias, dependendo de suas funcionalidades, como executar comandos Bash, funções Python, transferir dados ou executar consultas SQL.\n",
        "\n",
        "Principais operadores no Airflow:\n",
        "1. **BashOperator**: Executa comandos ou scripts bash diretamente na linha de comando.\n",
        "2. **PythonOperator**: Executa funções Python. É útil para executar lógica Python personalizada dentro de um DAG.\n",
        "3. **EmailOperator**: Envia emails. Geralmente usado para notificar falhas ou sucessos de tarefas.\n",
        "4. **PostgresOperator**: Executa comandos SQL em um banco de dados Postgres.\n",
        "5. **MySqlOperator**: Executa comandos SQL em um banco de dados MySQL.\n",
        "6. **S3ToGCSOperator**: Transfere arquivos do AWS S3 para o Google Cloud Storage (GCS).\n",
        "7. **SimpleHttpOperator**: Faz solicitações HTTP. Útil para chamadas de API.\n",
        "8. **DummyOperator**: Representa uma tarefa \"sem operação\", geralmente usada para testes ou como marcadores em um DAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo de DAG usando diferentes operadores no Airflow\n",
        "from airflow import DAG\n",
        "from airflow.operators.bash_operator import BashOperator\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.utils.dates import days_ago\n",
        "\n",
        "# Função Python a ser usada no PythonOperator\n",
        "def print_hello():\n",
        "    print(\"Hello from Python!\")\n",
        "\n",
        "# Definindo o DAG\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'start_date': days_ago(1),\n",
        "}\n",
        "dag = DAG(\n",
        "    'exemplo_dag',\n",
        "    default_args=default_args,\n",
        "    schedule_interval='@daily',\n",
        ")\n",
        "\n",
        "# Criando tarefas com diferentes operadores\n",
        "\n",
        "# BashOperator - Executa um comando Bash\n",
        "bash_task = BashOperator(\n",
        "    task_id='executar_script_bash',\n",
        "    bash_command='echo \"Hello Airflow!\"',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# PythonOperator - Executa uma função Python\n",
        "python_task = PythonOperator(\n",
        "    task_id='executar_funcao_python',\n",
        "    python_callable=print_hello,\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# DummyOperator - Não faz nada, usado como placeholder\n",
        "dummy_task = DummyOperator(\n",
        "    task_id='tarefa_placeholder',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Definindo dependências entre as tarefas\n",
        "bash_task >> python_task >> dummy_task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regras de Gatilho (Trigger Rules) no Airflow\n",
        "\n",
        "As **Regras de Gatilho** (Trigger Rules) no Airflow controlam quando uma tarefa deve ser executada com base no status das tarefas predecessoras. Por padrão, uma tarefa só será executada se todas as tarefas anteriores forem bem-sucedidas (trigger rule `all_success`). No entanto, há outras regras que podem ser configuradas, permitindo maior flexibilidade no controle do fluxo de trabalho.\n",
        "\n",
        "Principais regras de gatilho:\n",
        "1. **all_success** (padrão): Executa a tarefa somente se todas as predecessoras tiverem sucesso.\n",
        "2. **all_failed**: Executa a tarefa somente se todas as predecessoras falharem.\n",
        "3. **all_done**: Executa a tarefa independentemente do status das predecessoras (sucesso ou falha).\n",
        "4. **one_success**: Executa a tarefa se pelo menos uma predecessora for bem-sucedida.\n",
        "5. **one_failed**: Executa a tarefa se pelo menos uma predecessora falhar.\n",
        "6. **none_failed**: Executa a tarefa se nenhuma predecessora falhar (independente de estarem em sucesso ou ainda em execução).\n",
        "7. **none_skipped**: Executa a tarefa se nenhuma predecessora for pulada.\n",
        "8. **dummy**: Usada principalmente para testes, a tarefa será executada de forma imediata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo de DAG com diferentes regras de gatilho no Airflow\n",
        "from airflow import DAG\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.utils.dates import days_ago\n",
        "\n",
        "# Definindo o DAG\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'start_date': days_ago(1),\n",
        "}\n",
        "dag = DAG(\n",
        "    'exemplo_regras_gatilho',\n",
        "    default_args=default_args,\n",
        "    schedule_interval='@daily',\n",
        ")\n",
        "\n",
        "# Definindo tarefas\n",
        "tarefa1 = DummyOperator(\n",
        "    task_id='tarefa_1',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "tarefa2 = DummyOperator(\n",
        "    task_id='tarefa_2',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Tarefa 3 só será executada se uma das predecessoras for bem-sucedida\n",
        "tarefa3 = DummyOperator(\n",
        "    task_id='tarefa_3',\n",
        "    trigger_rule='one_success',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Tarefa 4 será executada independentemente do resultado das predecessoras\n",
        "tarefa4 = DummyOperator(\n",
        "    task_id='tarefa_4',\n",
        "    trigger_rule='all_done',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Definindo dependências\n",
        "tarefa1 >> tarefa3\n",
        "tarefa2 >> tarefa3\n",
        "tarefa3 >> tarefa4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DAGs Complexas no Airflow\n",
        "\n",
        "Uma **DAG complexa** no Airflow é composta por várias tarefas que podem ter interdependências complexas e lógicas de execução variadas. Essas DAGs envolvem múltiplos operadores, regras de gatilho personalizadas e podem ter uma grande quantidade de ramificações. A complexidade pode surgir quando se trabalha com muitas tarefas que têm diferentes condições de execução, como dependências de várias tarefas predecessoras ou regras de execução diferentes.\n",
        "\n",
        "\n",
        "Elementos comuns em DAGs complexas:\n",
        "1. **Dependências múltiplas**: Uma tarefa pode depender de várias tarefas predecessoras e pode ter várias tarefas sucessoras.\n",
        "2. **Ramificação condicional**: Usar o `BranchPythonOperator` para decidir qual caminho seguir com base em uma condição.\n",
        "3. **SubDAGs**: Utilizados para encapsular partes de um DAG dentro de um sub-DAG.\n",
        "4. **Trigger Rules complexas**: Uso avançado de regras de gatilho, como `one_failed` ou `all_done`, para controlar a execução.\n",
        "5. **Parallelismo**: Execução de tarefas em paralelo quando não há dependências entre elas.\n",
        "6. **Cross-DAG dependencies**: Dependências entre DAGs diferentes, onde a execução de uma tarefa depende do sucesso ou falha em outra DAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import PythonOperator, BranchPythonOperator\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.utils.dates import days_ago\n",
        "\n",
        "# Definindo o DAG\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'start_date': days_ago(1),\n",
        "}\n",
        "dag = DAG(\n",
        "    'dag_complexa_exemplo',\n",
        "    default_args=default_args,\n",
        "    schedule_interval='@daily',\n",
        ")\n",
        "\n",
        "# Função para ramificação\n",
        "def escolher_caminho():\n",
        "    # Condição para ramificação (exemplo simples)\n",
        "    return 'task_a' if True else 'task_b'\n",
        "\n",
        "# Tarefas do DAG\n",
        "inicio = DummyOperator(\n",
        "    task_id='inicio',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "branching = BranchPythonOperator(\n",
        "    task_id='branching',\n",
        "    python_callable=escolher_caminho,\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Definindo tarefas que seguem a ramificação\n",
        "task_a = DummyOperator(\n",
        "    task_id='task_a',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "task_b = DummyOperator(\n",
        "    task_id='task_b',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Tarefa final\n",
        "fim = DummyOperator(\n",
        "    task_id='fim',\n",
        "    dag=dag\n",
        ")\n",
        "\n",
        "# Definindo o fluxo de tarefas\n",
        "inicio >> branching\n",
        "branching >> [task_a, task_b]\n",
        "task_a >> fim\n",
        "task_b >> fim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## O que é TaskGroup no Airflow?\n",
        "\n",
        "O **TaskGroup** é uma funcionalidade do Apache Airflow que permite agrupar várias tarefas logicamente dentro de um DAG, facilitando a organização e visualização de pipelines complexos. Ele não altera a lógica de execução, mas melhora a **manutenção e monitoramento**, criando uma visão mais clara dos fluxos de trabalho.\n",
        "\n",
        "- **Benefícios**:\n",
        "  - Organização: Agrupa tarefas relacionadas, reduzindo a poluição visual no gráfico de dependências.\n",
        "  - Escalabilidade: Ajuda a manter o código mais limpo e modular.\n",
        "  - Monitoramento: Facilita o monitoramento e troubleshooting de grupos específicos de tarefas.\n",
        "\n",
        "- **Uso Comum**:\n",
        "  - Separar etapas como **extração**, **transformação** e **carga** em grupos dentro de um pipeline de ETL.\n",
        "  - Agrupar tarefas relacionadas a diferentes APIs ou processos distintos, mas interconectados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python import PythonOperator\n",
        "from airflow.utils.task_group import TaskGroup\n",
        "from datetime import datetime\n",
        "\n",
        "# Funções para serem executadas em cada tarefa\n",
        "def task_a():\n",
        "    print(\"Executando Tarefa A\")\n",
        "\n",
        "def task_b():\n",
        "    print(\"Executando Tarefa B\")\n",
        "\n",
        "def task_c():\n",
        "    print(\"Executando Tarefa C\")\n",
        "\n",
        "# Definição do DAG\n",
        "with DAG(\n",
        "    'exemplo_task_group',\n",
        "    default_args={'start_date': datetime(2024, 1, 1)},\n",
        "    schedule_interval='@daily',\n",
        "    catchup=False\n",
        ") as dag:\n",
        "\n",
        "    # Criando o grupo de tarefas\n",
        "    with TaskGroup('grupo_1', tooltip=\"Grupo 1 de tarefas\") as grupo_1:\n",
        "        tarefa_1 = PythonOperator(\n",
        "            task_id='tarefa_a',\n",
        "            python_callable=task_a\n",
        "        )\n",
        "        tarefa_2 = PythonOperator(\n",
        "            task_id='tarefa_b',\n",
        "            python_callable=task_b\n",
        "        )\n",
        "\n",
        "    # Outra tarefa fora do grupo\n",
        "    tarefa_3 = PythonOperator(\n",
        "        task_id='tarefa_c',\n",
        "        python_callable=task_c\n",
        "    )\n",
        "\n",
        "    # Definindo as dependências\n",
        "    grupo_1 >> tarefa_3\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
